---
title: "Comparing validation methods"
author: "me"
date: "4 joulukuuta 2019"
output: html_document
---
# 2. Validointimetodien vertailu

Verrataan neljällä eri metodilla laskettuja ennustustarkkuuksia.  
Onko validointimetodien välillä eroja? (vaikuttaako metodi ennustustarkkuuteen?) 
Onko ennustaminen helpompaa pa vai abu-aineistolla? (vaikuttaako aineistotyyppi ennustustarkkuuteen?) 
Kullakin lajilla ennustaminen voi olla ylipäätään helpompaa tai vaikeampaa, metodista tai aineistotyypistä riippumatta. (laji huomioitava random-muuttujana)

```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages<-c("readr","tidyr","plyr","dplyr","magrittr","purrr","data.table","plotrix","jtools","ggplot2","lme4","nlme","ggpubr","rstatix","Rmisc","emmeans")
lapply(packages,library,character.only=T)
```

Luetaan edellisessä osiossa lasketut tulokset sisälle:

```{r }
getwd()
res<-read.csv("results.csv",header=T,sep=",")
str(res)
```

Testaan, miten tulokset muuttuvat jos abu-aineistosta karsitaan pois muutamat havainnot, jotka perustuvat vain alle kymmeneen havaintoon. Tätä rajaa voidaan testailla.

```{r}
sort(res$P_D)

res$abu_D[res$P_D<10]=NA
res$abu_C[res$P_D<10]=NA
```

Jos minimihavaintorajana pidetään kymmentä, **pohjansirkku ja pyy putoavat pois** (muuttuvat NA:ksi). Tarkistan NA-havaintojen määrät jokaiselle metodille.

```{r}
sum(is.na(res$pa_A))
sum(is.na(res$pa_B))
sum(is.na(res$pa_C))
sum(is.na(res$pa_D))
sum(is.na(res$abu_A))
sum(is.na(res$abu_B))
sum(is.na(res$abu_C))
sum(is.na(res$abu_D))
```

Eli aineisto ei ole enää ihan täydellisen balanssissa. Pohjansirkulta ja pyyltä puuttuvat arvot abu-aineistosta C ja D menetelmille.


## 2.1 Keskiarvot ja keskivirheet

Lasketaan ennustustarkkuuksien keskiarvot ja keskivirheet kullekin metodi/aineistotyyppi-yhdistelmälle:

```{r }
#Compute means and standard errors
knitr::kable(res %>% dplyr::select(2:9)%>%colMeans(.,na.rm = T),digits=3)
knitr::kable(res %>% dplyr::select(2:9)%>%std.error(),digits=3)

#aineiston jakauma, boxplot
boxplot(res[c(-1,-10)])
abline(h=0)
```

Pitäisikö kuvaajissa pitää pa ja abu erillään?


## 2.2 Analyysit

### 2.2.1 Aineiston muokkaus

Mallintamista varten luodaan uusi muuttuja, joka kertoo onko käytetty aineisto pa- vai abu-aineistoa. Muutan myös method-muuttujan koodausta hieman.

```{r}
#aineiston muokkaus:
res_pa=res[,1:5]
res_pa=gather(res_pa,"method","accuracy",2:5)
res_pa$method=as.factor(revalue(res_pa$method,c("pa_A"="A","pa_B"="B","pa_C"="C","pa_D"="D")))
res_pa$pa=as.factor("pa")

res_abu=res[,c(1,6:9)]
res_abu=gather(res_abu,"method","accuracy",2:5)
res_abu$method=as.factor(revalue(res_abu$method,c("abu_A"="A","abu_B"="B","abu_C"="C","abu_D"="D")))
res_abu$pa=as.factor("abu")

res2=rbind(res_abu,res_pa)
str(res2)
summary(res2)

#tallennetaan taulukko, muista, että mukana NA:ta!!
write.csv(res2,"results_with_NA.csv",row.names = F)
```

Teen uuden kuvaajan tällä aineistolla.

```{r}
ggplot(res2,aes(x=method, y=accuracy))+geom_boxplot()+facet_grid(.~pa)
```


### 2.2.2 Lineaarinen sekamalli

Alkuperäinen idea oli käyttää lineaarista sekamuuttujamallia, jossa ennustustarkkuutta selittävät metodi ja aineistotyyppi sekä niiden välinen interaktio. Lisäksi malli huomioi lajin random-tekijänä.

Aloitan kuitenkin harjoituksen vuoksi ensin ihan perus lineaarisella mallilla, ilman random-tekijää.

```{r}
m0=lm(accuracy~method*pa,data=res2,na.action = "na.exclude")
summary(m0)
drop1(m0,test="F")
```

Tämä malli näyttää, että selittävien muuttujien interaktio on merkitsevä. Huomaa, että laitoin malliin argumentin na.action="na.exclude" koska muuten seuraavassa kohdassa fitted arvojen laskeminen ei onnistu neljän puuttuvan abu_C ja abu_D arvon takia.


Mallin validointi residuaalien kuvaajien avulla:

```{r,out.width = '100%'}
E1=rstandard(m0)
F1=fitted(m0)
par(mfrow=c(2,2), mar=c(5,5,2,2))
plot(x=F1,y=E1,xlab="fitted",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~method,xlab="method",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~pa,xlab="pa",ylab="residuals",data=res2)
abline(h=0,lty=2)
par(mfrow=c(1,1), mar=c(5,5,2,2))
boxplot(E1~species,xlab="species",ylab="residuals",data=res2)
abline(h=0,lty=2)
```

Mallin validointi paljastaa, että 'species' sisältää vielä vaihtelua. Se pitäisi ottaa mukaan malliin. Tehdään siis sekamalli, jossa 'species' on mukana random-tekijänä (120 lajia, 8 havaintoa per laji (pa/abu -aineisto + A/B/C/D -metodi)).  

Laji siis random-tekijäksi mukaan. Testataan "REML"-asetuksella, kumpi on parempi.

```{r}
A1=gls(accuracy ~ method*pa, method="REML", data=res2,na.action="na.exclude")
A2=lme(accuracy ~ method*pa, random=~1|species, data=res2,method="REML",na.action="na.exclude")

#tai eri funktiolla (lme4)
#A2b=lmer(accuracy ~ method*pa + (1|species), data=res2,REML = T,na.action="na.exclude")

anova(A1,A2)
AIC(A1,A2)
```

Sekamalli näyttäisi olevan parempi.

Muitakin random-rakenteita voisi testata. Mutta ovatko ne mielekkäitä? 

Tämä [artikkeli](https://www.sciencedirect.com/science/article/pii/S0749596X12001180) neuvoo maksimoimaan random-rakenteen. Mutta artikkelin luettuani en olekaan enää ollenkaan kärryillä siitä, mitä asioita random-muuttujaksi pitäisi laittaa.

-Eikö pa-muuttuja eli aineistotyyppi voisi olla vain random-puolella? Omana interceptinään? Olisiko malli A4 maksimaalinen random-rakenne, jonka tutkimusasetelmamme sallii?

-Artikkelin esimerkissä ainoa fixed-muuttuja on se muuttuja, josta ollaan kiinnostuttu. Mitä eroa on sillä, että pa laitetaan fixed-osaan interaktioon metodin kanssa vs. pa on vain random-puolella?

```{r}
#muita vaihtoehtoja random-rakenteen testaamiseksi:
A3=lmer(accuracy ~ method + (1+method|species), data=res2,REML = T,na.action="na.exclude")

A4=lmer(accuracy ~ method + (1+method|species)+(1|pa), data=res2,REML = T,na.action="na.exclude")

#tämmöinenkin malli tässä oli aluksi..
#A5=lme(accuracy~method*pa,data=res2,random=~1+method*pa|species,method="REML")

AIC(A2,A3,A4)
```

Vaihtoehtoiset mallit eivät kaikki näytä toimivan. Enkä tiedä onko niissä mitään järkeä. 


Keskitytään sitten fixed-osaan. Fixed-osan mallin sovituksessa käytetään "ML"-asetuksia.Tehdään neljä mallia, jotka sisältävät eri kombinaatiot muuttujista method ja pa. Vertaillaan näitä keskenään.

```{r}
A2full=lme(accuracy~method*pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.a=lme(accuracy~method+pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.b=lme(accuracy~method,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.c=lme(accuracy~pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.d=lme(accuracy ~ 1, random=~1|species, data=res2,method="ML",na.action="na.exclude")

anova(A2full,A2.a)
anova(A2full)
AIC(A2full,A2.a,A2.b,A2.c,A2.d)
```

Jo ensimmäinen anova-vertailu antaa tulokseksi, että interaktio on merkitsevä, joten molemmat muuttujat ja niiden interaktio on hyvä pitää mallissa. AIC-vertailu antaa saman tuloksen.  

Lopullinen malli on siis A2full, joka ajetaan vielä kerran "REML"-asetuksilla.

```{r}
A2full=lme(accuracy~method*pa,data=res2,random=~1|species,method="REML",na.action="na.exclude")
summary(A2full)
anova(A2full)
```

Metodin ja data tyypin interaktio on merkitsevä.

Kokeilen testata metodien ja data tyypin välisiä eroja emmeans-paketin avulla.

```{r}
emmeans(A2full, list(pairwise ~ method|pa))
emmeans(A2full, specs=pairwise ~ method:pa)

emm2 = emmeans(A2full, specs = pairwise ~ method|pa, adjust="bonferroni")
emm2

emm3 = emmeans(A2full, specs =pairwise ~ pa|method, adjust="bonferroni")
emm3


```

Tulokset mietityttävät koska tämän testin mukaan pa-aineistolla metodit A ja B sekä C ja D eivät eroa toisistaan. Seuraavassa osiossa teen t-testejä mielestäni samalla tavalla (bonferroni), mutta tulokset ovat erilaiset. Mielestäni nämä tulokset vaikuttavat järkevämmiltä, ainakin kun katsoo luottamusvälejä ja niiden päällekkäisyyksiä.

Abu-aineistolla vain C ja D metodit eivät eroa toisistaan. 

Pa ja abu aineistot eroavat toisistaan kaikilla muilla metodeilla paitsi D:llä.

Mallin validointi residuaalien avulla:

```{r}
E1=resid(A2full, type="normalized")
F1=fitted(A2full)
par(mfrow=c(2,2), mar=c(5,5,2,2))
plot(x=F1,y=E1,xlab="fitted",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~method,xlab="method",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~pa,xlab="pa",ylab="residuals",data=res2)
abline(h=0,lty=2)
par(mfrow=c(1,1), mar=c(5,5,2,2))
boxplot(E1~species,xlab="species",ylab="residuals",data=res2)
abline(h=0,lty=2)

plot(A2full)
qqnorm(A2full)
qqnorm(A2full,~ranef(.),col=1)
intervals(A2full)
```

Eli ennustustarkkuuteen vaikuttavat metodin ja aineiston yhdistelmä. Residuaalit näyttävät ihan ok:lta.


### 2.2.3 ANOVA, pairwise t-tests

Vaihtoehtoinen analyysi. Kokeilen kaikenlaista huvin ja hyödyn vuoksi.

```{r}
#stats
res2 %>%
  group_by(method,pa)%>%
  get_summary_stats(accuracy, type = "mean_sd")
```

```{r}
#visualization
bxp <- ggboxplot(
  res2, x = "method", y = "accuracy",
  color = "pa", palette = "jco"
  )
bxp
```

```{r}
#outliers
res2 %>%
  group_by(method,pa) %>%
  identify_outliers(accuracy)

#normality
res2 %>%
  group_by(method,pa) %>%
  shapiro_test(accuracy)

#qqplot
ggqqplot(res2, "accuracy", ggtheme = theme_bw()) +
  facet_grid(method ~ pa, labeller = "label_both")
```

Ei kai kummempaa aineistossa. Outliereitä paljon testin mukaan. Ei kuitenkaan aivan ekstreemejä. En toistaiseksi käyttänyt liikaa aikaa näiden tulkitsemiseen.

```{r}
#the test
res.aov <- anova_test(
  data = res2, dv = accuracy, wid = species,
  within = c(pa, method)
  )
get_anova_table(res.aov)
```

Data tyyppi (pa) ja method-interaktio merkitsevä.

```{r}
# Effect of method at both data types
one.way <- res2 %>%
  group_by(pa) %>%
  anova_test(dv = accuracy, wid = species, within = method) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
one.way
```

Metodit eroavat toisistaan kummallakin aineistotyypillä.

Mitkä metodit eroavat toisistaan?

```{r}
# Pairwise comparisons between methods
pwc <- res2 %>%
  group_by(pa) %>%
  pairwise_t_test(
    accuracy ~ method, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
```

Pa aineistolla kaikki metodit eroavat toisistaan. Hmm? Aiemmin emmeans-funktiolla laskin, että pa-aineistolla A/B ja C/D vertailuissa eroja ei löytynyt. Kumpi on oikein?

Abu-aineistolla vain C/D metodit eroavat toisistaan. 

```{r}
# Pairwise comparisons between data types
pwc <- res2 %>%
  group_by(method) %>%
  pairwise_t_test(
    accuracy ~ pa, paired = TRUE,
    p.adjust.method = "bonferroni"
    )
pwc
```

sama tulos kuin yllä koska vain kaksi data tyyppiä. 

```{r}
# Effect of pa at each method
one.way <- res2 %>%
  group_by(method) %>%
  anova_test(dv = accuracy, wid = species, within = pa) %>%
  get_anova_table() %>%
  adjust_pvalue(method = "bonferroni")
one.way
```

Simple main effect of data type (pa) was significant for all other methods except for D.


```{r}
# Visualization: box plots with p-values
pwc <- pwc %>% add_xy_position(x = "method")
bxp + 
  stat_pvalue_manual(pwc, tip.length = 0, hide.ns = TRUE) +
  labs(
    subtitle = get_test_label(res.aov, detailed = TRUE),
    caption = get_pwc_label(pwc)
  )
```

Sinänsä huono kuvaaja koska tästä ei näy kumman, pa vai abu aineiston C/D vertailu oli merkitsevä. Ja muutenkin viivat menevät pahasti päällekkäin.


## 2.3 Muita kuvaajia


### 2.3.1 Boxplotti

Perus boxplottikuvaaja:

```{r}
boxplot(accuracy~pa*method,data=res2)
ggplot(res2, aes(x = method, y = accuracy, interaction = pa, colour = pa)) + geom_boxplot() 
```


### 2.3.2 Kahden metodin korrelaatioplotti 

Alkuperäinen idea kuvaajasta oli tämä:

```{r, out.width="100%"}
# Piirretään kuvaaja, Fig1

#määritetään kuvalle raamit ja nimi
Line=c(-1,1)
Line2=c(-1,1)
Line3=c(0,0)

Line=cbind(Line,Line2)
Line=cbind(Line,Line3)

Line=as.data.frame(Line)

#pdf("Fig123.pdf")
jpeg("Fig123.jpeg")
#png("Fig1abcdef.png")

#määrittää 3x3 matriisin johon kuvat piirretään
layout(matrix(c(1,2,7,3,4,7,5,6,7), 3, 3, byrow = TRUE))

# a)
plot(pa_B~pa_A,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (A)",
     ylab="Prediction accuracy (B)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"a) Distribution",cex=0.8)

# b)
plot(abu_B~abu_A,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (A)",
     ylab="Prediction accuracy (B)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"b) Abundance",cex=0.8)

# c)
plot(pa_D~pa_C,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (C)",
     ylab="Prediction accuracy (D)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"c) Distribution",cex=0.8)

# d)
plot(abu_D~abu_C,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (C)",
     ylab="Prediction accuracy (D)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"d) Abundance",cex=0.8)

#dev.off()
```

En saa kuvaajaa näkymään tässä mutta se löytyy kässäristä.

Tätä pitäisi vielä miettiä, mitä plotataan ja mitä vasten? Alun perin verrattiin metodi D:tä pa/abu_past-arvoihin eli vähän sama kuin vertailu metodi A:han. siis, voitaisiinko jo hyvin yksinkertaisella validointimenetelmällä saada samoja tuloksia kuin monimutkaisemmalla metodilla?


### 2.3.3 Luottamusvälit

```{r}
library(Rmisc)
stat <- summarySE(res2, measurevar="accuracy", groupvars=c("method","pa"),na.rm = T)
stat
stat$lower=stat$accuracy-stat$ci
stat$upper=stat$accuracy+stat$ci
round(stat[,4:9],digits = 3)
names(stat)[2] <- "Data_type"

pd <- position_dodge(0.2) # move them .05 to the left and right

# Black error bars - notice the mapping of 'group=supp' -- without it, the error
# bars won't be dodged!
ggplot(stat, aes(x=method, y=accuracy, group=Data_type)) + 
    geom_errorbar(aes(ymin=accuracy-ci, ymax=accuracy+ci), colour="black", width=.2, position=pd) +
    geom_point(aes(shape=Data_type),position=pd, size=4)+
    scale_shape_manual(values=c(19,17))+
    ylab("Prediction accuracy") +
    xlab("Validation method") +
    theme_bw() +
    theme(legend.justification=c(1,1),
          legend.position=c(0.95,0.95),
          legend.box.background=element_rect())  +             # Position legend in bottom right
    theme(text = element_text(size = 17)) +
    labs(fill = "Data type")
```

