---
title: "Comparing validation methods"
author: "me"
date: "4 joulukuuta 2019"
output: html_document
---
# 2. Validointimetodien vertailu

Verrataan neljällä eri metodilla laskettuja ennustustarkkuuksia.  
Onko validointimetodien välillä eroja? (vaikuttaako metodi ennustustarkkuuteen?) 
Onko ennustaminen helpompaa pa vai abu-aineistolla? (vaikuttaako aineistotyyppi ennustustarkkuuteen?) 
Kullakin lajilla ennustaminen voi olla ylipäätään helpompaa tai vaikeampaa, metodista tai aineistotyypistä riippumatta. (laji huomioitava random-muuttujana)

```{r , include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
packages<-c("readr","tidyr","plyr","dplyr","magrittr","purrr","data.table","plotrix","jtools","ggplot2","lme4","nlme","ggpubr","rstatix")
lapply(packages,library,character.only=T)
```

Luetaan edellisessä osiossa lasketut tulokset sisälle:

```{r }
getwd()
res<-read.csv("results.csv",header=T,sep=",")
str(res)
```

Testaan, miten tulokset muuttuvat jos abu-aineistosta karsitaan pois muutamat havainnot, jotka perustuvat vain alle kymmeneen havaintoon. Tätä rajaa voidaan testailla.

```{r}
res$abu_D[res$P_D<10]=NA
res$abu_C[res$P_D<10]=NA
```

Jos minimihavaintorajana pidetään kymmentä, pohjansirkku ja pyy putoavat pois.

## 2.1 Keskiarvot ja keskivirheet

Lasketaan ennustustarkkuuksien keskiarvot ja keskivirheet kullekin metodi/aineistotyyppi-yhdistelmälle:

```{r }
#Compute means and standard errors
res %>% dplyr::select(2:9)%>%colMeans(.,na.rm = T)
res %>% dplyr::select(2:9)%>%std.error()

#kuvaaja
boxplot(res[c(-1,-10)])
abline(h=0)
```

Kuvaajissa olisi varmaan hyvä pitää pa ja abu erillään?


## 2.2 Analyysi

### 2.2.1 Aineiston muokkaus

Mallintamista varten luodaan uusi dummy-muuttuja, joka kertoo onko käytetty aineisto pa- vai abu-aineistoa. Muutan myös method-muuttujan koodausta hieman.

```{r}
#aineiston muokkaus:
res_pa=res[,1:5]
res_pa=gather(res_pa,"method","accuracy",2:5)
res_pa$method=as.factor(revalue(res_pa$method,c("pa_A"="A","pa_B"="B","pa_C"="C","pa_D"="D")))
res_pa$pa=as.factor("pa")

res_abu=res[,c(1,6:9)]
res_abu=gather(res_abu,"method","accuracy",2:5)
res_abu$method=as.factor(revalue(res_abu$method,c("abu_A"="A","abu_B"="B","abu_C"="C","abu_D"="D")))
res_abu$pa=as.factor("abu")

res2=rbind(res_pa,res_abu)
str(res2)
summary(res2)

#tallennetaan taulukko, muista, että mukana NA:ta!!
write.csv(res2,"results_with_NA.csv",row.names = F)
```

Teen uuden kuvaajan tällä aineistolla.

```{r}
ggplot(res2,aes(x=method, y=accuracy))+geom_boxplot()+facet_grid(.~pa)
```




### 2.2.2. Testaus

Alkuperäinen idea oli käyttää lineaarista sekamuuttujamallia, jossa ennustustarkkuutta selittävät metodi ja aineistotyyppi sekä niiden välinen interaktio. Lisäksi malli huomioi lajin random-tekijänä.

Aloitan kuitenkin harjoituksen vuoksi ensin ihan perus lineaarisella mallilla, ilman random-tekijää.

```{r}
m0=lm(accuracy~method*pa,data=res2,na.action = "na.exclude")
summary(m0)
drop1(m0,test="F")
```

Tämä malli näyttää, että selittävien muuttujien interaktio on merkitsevä. Huomaa, että laitoin malliin argumentin na.action="na.exclude" koska muuten seuraavassa kohdassa fitted arvojen laskeminen ei onnistu neljän puuttuvan abu_C ja abu_D arvon takia.


Mallin validointi residuaalien kuvaajien avulla:

```{r,out.width = '100%'}
E1=rstandard(m0)
F1=fitted(m0)
par(mfrow=c(2,2), mar=c(5,5,2,2))
plot(x=F1,y=E1,xlab="fitted",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~method,xlab="method",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~pa,xlab="pa",ylab="residuals",data=res2)
abline(h=0,lty=2)
par(mfrow=c(1,1), mar=c(5,5,2,2))
boxplot(E1~species,xlab="species",ylab="residuals",data=res2)
abline(h=0,lty=2)
```

Mallin validointi paljastaa, että 'species' sisältää vielä vaihtelua. Se pitäisi ottaa mukaan malliin. Tehdään siis sekamalli, jossa 'species' on mukana random-tekijänä (120 lajia, 8 havaintoa per laji (pa/abu -aineisto + A/B/C/D -metodi)).  

Laji siis random-tekijäksi mukaan. Testataan "REML"-asetuksella, kumpi on parempi.

```{r}
A1=gls(accuracy~method*pa,method="REML",data=res2,na.action="na.exclude")

A2=lme(accuracy~method*pa,random=~1|species,data=res2,method="REML",na.action="na.exclude")

anova(A1,A2)
```

Sekamalli näyttäisi olevan parempi. 

Muitakin random-rakenteita voisi testata. Mutta ovatko ne mielekkäitä? 

```{r}
#muita vaihtoehtoja random-rakenteen testaamiseksi:
#A3=lme(accuracy~method*pa,data=res2,random=~1+method|species,method="REML")
A4=lme(accuracy~method*pa,data=res2,random=~1+pa|species,method="REML",na.action="na.exclude")
#A5=lme(accuracy~method*pa,data=res2,random=~1+method*pa|species,method="REML")
#päätimme jätttää testaamatta todettuamme, etteivät nämä ole kiinnostavia sisänsä

anova(A2,A4)
```

A4 olisi itseasiassa ollut vielä parempi mutta onko se mielekäs? Pysytään silti A2 mallissa.

```{r}
summary(A2)
anova(A2)
```

Mallissa A2 metodi ja aineistotyyppi sekä niiden interaktio näyttävät olevan merkitseviä.

Tehdään seuraavaksi mallin validointi residuaalien ja kuvaajien avulla:

```{r,out.width="100%"}
E1=resid(A2, type="normalized")
F1=fitted(A2)

par(mfrow=c(2,2), mar=c(5,5,2,2))
plot(x=F1,y=E1,xlab="fitted",ylab="residuals")
abline(h=0,lty=2)
boxplot(E1~method,xlab="method",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~pa,xlab="pa",ylab="residuals",data=res2)
abline(h=0,lty=2)
par(mfrow=c(1,1), mar=c(5,5,2,2))
boxplot(E1~species,xlab="species",ylab="residuals",data=res2)
abline(h=0,lty=2)
```


Residuaalit näyttää ok:lta. Lajin kohdalla ne hieman seilaavat mutta onko tämä kuinka paha/hyvä?  

Teen huvikseen mallin validoinnin myös mallille A4:

```{r}
#sama validointi jos olisikin valittu A4:
E1=resid(A4, type="normalized")
F1=fitted(A4)

par(mfrow=c(2,2), mar=c(5,5,2,2))
plot(x=F1,y=E1,xlab="fitted",ylab="residuals")
abline(h=0,lty=2)
boxplot(E1~method,xlab="method",ylab="residuals",data=res2)
abline(h=0,lty=2)
boxplot(E1~pa,xlab="pa",ylab="residuals",data=res2)
abline(h=0,lty=2)
par(mfrow=c(1,1), mar=c(5,5,2,2))
boxplot(E1~species,xlab="species",ylab="residuals",data=res2)
abline(h=0,lty=2)
```

Ilmeisesti aika samanlaiset residuaalit. Pysytään siis edelleen mallissa A2.

Keskitytään sitten fixed-osaan. Fixed-osan mallin sovituksessa käytetään "ML"-asetuksia.Tehdään neljä mallia, jotka sisältävät eri kombinaatiot muuttujista method ja pa. Vertaillaan näitä keskenään.

```{r}
A2full=lme(accuracy~method*pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.a=lme(accuracy~method+pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.b=lme(accuracy~method,data=res2,random=~1|species,method="ML",na.action="na.exclude")
A2.c=lme(accuracy~pa,data=res2,random=~1|species,method="ML",na.action="na.exclude")

anova(A2full,A2.a)
AIC(A2full,A2.a,A2.b,A2.c)
```

Jo ensimmäinen vertailu antaa tulokseksi, että interaktio on merkitsevä, joten molemmat muuttujat on hyvä pitää mallissa. AIC-vertailu antaa saman tuloksen.  

Lopullinen malli on siis A2full, joka ajetaan vielä kerran "REML"-asetuksilla.

```{r}
A2full=lme(accuracy~method*pa,data=res2,random=~1|species,method="REML",na.action="na.exclude")
summary(A2full)

plot(A2full)
qqnorm(A2full)
qqnorm(A2full,~ranef(.),col=1)
intervals(A2full)
```

Eli ennustustarkkuuteen vaikuttavat metodin ja aineiston yhdistelmä. Huonoimmat tulokset saa abu-aineistolla ja metodilla D.   


## 2.3 Kuvaaja

Boxplotti voisi näyttää tältä:
```{r}
boxplot(accuracy~pa*method,data=res2)

ggplot(res2, aes(x = method, y = accuracy, interaction = pa, colour = pa)) + geom_boxplot() 
```


Alkuperäinen idea kuvaajasta oli tämä:


```{r, out.width="100%"}
# Piirretään kuvaaja, Fig1

#määritetään kuvalle raamit ja nimi
Line=c(-1,1)
Line2=c(-1,1)
Line3=c(0,0)

Line=cbind(Line,Line2)
Line=cbind(Line,Line3)

Line=as.data.frame(Line)

#pdf("Fig1.pdf")
#jpeg("Fig1abcdef.jpeg")
#png("Fig1abcdef.png")

#määrittää 3x3 matriisin johon kuvat piirretään
layout(matrix(c(1,2,7,3,4,7,5,6,7), 3, 3, byrow = TRUE))

# a)
plot(pa_B~pa_A,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (A)",
     ylab="Prediction accuracy (B)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"a) Distribution",cex=0.8)

# b)
plot(abu_B~abu_A,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (A)",
     ylab="Prediction accuracy (B)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"b) Abundance",cex=0.8)

# c)
plot(pa_D~pa_C,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (C)",
     ylab="Prediction accuracy (D)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"c) Distribution, 2 km",cex=0.8)

# d)
plot(abu_D~abu_C,data=res,xlim=c(-1,1),
     ylim=c(-1,1),cex.axis=0.8,xlab="Prediction accuracy (C)",
     ylab="Prediction accuracy (D)")
lines(Line$Line,Line$Line2,lty="dashed")
lines(Line$Line,Line$Line3,col="grey",lty="dashed")
lines(Line$Line3,Line$Line,col="grey",lty="dashed")

text(-0.5,0.8,"d) Abundance, 2 km",cex=0.8)

#dev.off()
```

Tätä pitäisi vielä miettiä, mitä plotataan ja mitä vasten? Alun perin verrattiin metodi D:tä pa/abu_past-arvoihin eli vähän sama kuin vertailu metodi A:han. siis, voitaisiinko jo hyvin yksinkertaisella validointimenetelmällä saada samoja tuloksia kuin monimutkaisemmalla metodilla?


Plottaus esitelmään:

```{r}
res3=subset(res2,method=="B"|method=="D", select=c(accuracy,pa, species,method))
stat <- summarySE(res3, measurevar="accuracy", groupvars=c("method","pa"),na.rm = T)
stat

pd <- position_dodge(0.1) # move them .05 to the left and right

# Standard error of the mean
ggplot(stat, aes(x=method, y=accuracy, colour=pa)) + 
    geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1, position=pd)+
    geom_point(position=pd)

stat$method=revalue(stat$method, c("B"="traditional", "D"="novel"))


# Use 95% confidence interval instead of SEM
ggplot(stat, aes(x=method, y=accuracy, colour=pa)) + 
    geom_errorbar(aes(ymin=accuracy-ci, ymax=accuracy+ci), width=.1, position=pd) +
    geom_line(position=pd) +
    geom_point(position=pd)

# Black error bars - notice the mapping of 'group=supp' -- without it, the error
# bars won't be dodged!
ggplot(stat, aes(x=method, y=accuracy, colour=pa, group=pa)) + 
    geom_errorbar(aes(ymin=accuracy-ci, ymax=accuracy+ci), colour="black", width=.2, position=pd) +
    geom_point(position=pd, size=6)+
    ylab("Model transferability") +
    scale_colour_hue(name="Data type",    # Legend label, use darker colors
                     breaks=c("pa", "abu"),
                     labels=c("Presence/absence", "Abundance"),
                     l=40) +                    # Use darker colors, lightness=40
    theme_bw() +
    theme(legend.justification=c(1,1),
          legend.position=c(0.95,0.95),
          legend.box.background=element_rect())  +             # Position legend in bottom right
    theme(text = element_text(size = 20))


#plottailua
ggplot(res3, aes(x = method, y = accuracy, interaction = pa, colour = pa)) + geom_boxplot() 
```


Vaihtoehtoinen analyysi:

```{r}
#stats
res2 %>%
  group_by(method,pa)%>%
  get_summary_stats(accuracy, type = "mean_sd")

#visualization
bxp <- ggboxplot(
  res2, x = "method", y = "accuracy",
  color = "pa", palette = "jco"
  )
bxp

#outliers
res2 %>%
  group_by(method,pa) %>%
  identify_outliers(accuracy)

#normality
res2 %>%
  group_by(method,pa) %>%
  shapiro_test(accuracy)

#qqplot
ggqqplot(res2, "accuracy", ggtheme = theme_bw()) +
  facet_grid(method ~ pa, labeller = "label_both")

#the test
res.aov <- anova_test(
  data = res2, dv = accuracy, wid = species,
  within = c(pa, method)
  )
get_anova_table(res.aov)

#jatkuu

```


